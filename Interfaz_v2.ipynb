{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://investigacion.unirioja.es/img/ur-ddb7a50ad445db722a463e04d6373b1e.png\" width=\"400\" height=\"400\" align=\"right\" margin=80px;>\n",
    "<p align=\"center\">\n",
    "<p><strong><u><span style=\"font-size: 20px;\">Clasificador de Murci&eacute;lagos</span></u></strong></p>\n",
    "<ul>\n",
    "    <li>Ppip: Pipistrellus pipistrellus &nbsp;(Schreber, 1774) &nbsp;Murci&eacute;lago enano</li>\n",
    "    <li>Ppyg: Pipistrellus pygmaeus &nbsp;(Leach, 1825) &nbsp;Murci&eacute;lago de Cabrera</li>\n",
    "    <li>Pnat: Pipistrellus nathusii &nbsp;(Keyserling &amp; Blasius, 1839) &nbsp;Murci&eacute;lago de Nathusius</li>\n",
    "    <li>Pkuh: Pipistrellus kuhlii &nbsp;(Kuhl, 1817) &nbsp;Murci&eacute;lago de borde claro</li>\n",
    "    <li>Hsav: Hypsugo savii &nbsp;(Bonaparte, 1837) &nbsp;Murci&eacute;lago monta&ntilde;ero</li>\n",
    "    <li>Msch: Miniopterus schreibersii &nbsp;(Kuhl, 1817) &nbsp;Murci&eacute;lago de cueva</li>\n",
    "    <li>Plec: Plecotus</li>\n",
    "    <li>Myot: Myotis</li>\n",
    "    <li>Barb: Barbastella</li>\n",
    "    <li>BACK: ruido de fondo(insectos u otro tipo)</li>\n",
    "    <li>NOISE: ruido</li>\n",
    "</ul>\n",
    "<img src=\"https://www.researchgate.net/profile/Kate-Jones-7/publication/267212641/figure/fig2/AS:295588781412358@1447485265852/A-spectrogram-of-a-sequence-of-Pipistrellus-pipistrellus-echolocation-calls-Hanning.png\" width=\"400\" height=\"400\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rasieira/anaconda3/envs/murcielagos/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, glob, random, time, sys, pickle\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa, librosa.display\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# import torch.optim as optim\n",
    "import torch_optimizer as optim\n",
    "from torchvision import transforms, models, datasets\n",
    "# from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "# from torchlibrosa.augmentation import SpecAugmentation\n",
    "from torchaudio.transforms import AmplitudeToDB\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from datetime import datetime\n",
    "from shutil import copyfile\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from tqdm.notebook import trange\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, ConfusionMatrixDisplay, confusion_matrix\n",
    "from skimage.transform import resize\n",
    "from PIL import Image, ImageOps\n",
    "np.set_printoptions(suppress=True)\n",
    "import progressbar\n",
    "import timm\n",
    "from timm.models.efficientnet import tf_efficientnet_b0_ns, tf_efficientnet_b1_ns, tf_efficientnet_b2_ns, tf_efficientnet_b3_ns, tf_efficientnet_b4_ns\n",
    "from os import walk\n",
    "from pandas import DataFrame\n",
    "from fastai.vision.widgets import *\n",
    "import zipfile\n",
    "from ipyfilechooser import FileChooser\n",
    "import itertools\n",
    "from progress.bar import Bar\n",
    "\n",
    "import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    num_clases = 10,\n",
    "    spec = {\n",
    "        'n_fft' : 3072,\n",
    "        'hop_length' : 768,\n",
    "        'fmax' : 96000,\n",
    "        'fmin' : 8000,\n",
    "        'new_fmin':10000,\n",
    "        'new_fmax':120000,\n",
    "#         'new_fft':3072//2,\n",
    "#         'new_hop_length':768//16,\n",
    "        'new_hop_length':768//8,\n",
    "        'new_fft':3072//2,\n",
    "        'tramo': 1.5,\n",
    "        'paso': 0.75,\n",
    "        'batch':1\n",
    "    }\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "SPECAUGMENT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SedDataset:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):  \n",
    "        name_files=[]\n",
    "        images=[]\n",
    "        intervalos=[]\n",
    "        record = self.df.iloc[idx]\n",
    "        name_file = record['full_path']\n",
    "        y, sr = sf.read(name_file)\n",
    "        len_crop = int(args.spec['tramo'] * sr)\n",
    "        paso=int(args.spec['paso'] * sr)\n",
    "        inf=0\n",
    "        sup=len_crop\n",
    "        i=0\n",
    "        t=len(y)\n",
    "        duracion=librosa.get_duration(filename=name_file)\n",
    "        while len(y)<len_crop:\n",
    "            y = np.concatenate([y, y])\n",
    "        while sup<=len(y):\n",
    "            aux=y[inf:sup]\n",
    "            if len(aux)<len_crop:\n",
    "                aux=y[len(y)-len_crop:len(y)]\n",
    "            f_min = args.spec['fmin']\n",
    "            f_max = args.spec['fmax']\n",
    "            if sr==192000:\n",
    "                n_fft= args.spec['n_fft'] // 2\n",
    "                hop_length = args.spec['hop_length'] // 2\n",
    "            if sr==256000:\n",
    "                n_fft= args.spec['n_fft'] * 2 // 3\n",
    "                hop_length = args.spec['hop_length'] * 2 // 3\n",
    "            if sr==384000:\n",
    "                n_fft= args.spec['n_fft']\n",
    "                hop_length = args.spec['hop_length']\n",
    "\n",
    "            frecuencias = np.arange(0, 1 + n_fft / 2) * sr / n_fft\n",
    "            indices_freq = (frecuencias >= f_min) & (frecuencias <= f_max)\n",
    "            img = np.abs(librosa.stft(aux, n_fft=n_fft, hop_length=hop_length, win_length=n_fft, window='hamming'))**2\n",
    "            img = librosa.power_to_db(img, ref=np.max)\n",
    "            img = img[indices_freq,:]\n",
    "            img = torch.from_numpy(img)\n",
    "            images.append(img)\n",
    "            name_files.append(name_file)\n",
    "            intervalos.append([inf/sr,sup/sr])\n",
    "            inf=inf+paso\n",
    "            sup=sup+paso\n",
    "            i=i+1\n",
    "        return {\"images\" : images,'name_files' : name_files,'intervalos':intervalos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SedDatasetNoInterval:\n",
    "    def __init__(self, df, audio_transform=None, modo=\"train\"):\n",
    "        self.audio_transform = audio_transform\n",
    "        self.modo = modo\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        record = self.df.iloc[idx]\n",
    "        name_file = record['full_path']\n",
    "        y, sr = sf.read(name_file)\n",
    "        len_crop = int(args.spec['tramo'] * sr)\n",
    "        \n",
    "        # Agumentation in audio\n",
    "        if self.audio_transform:\n",
    "            y = self.audio_transform(samples=y, sample_rate=sr)\n",
    "        \n",
    "        f_min = args.spec['new_fmin']\n",
    "        f_max = args.spec['new_fmax']\n",
    "\n",
    "        # Frecuencias y hop_length proporcionales a la sr\n",
    "        if sr==192000:\n",
    "            n_fft= args.spec['new_fft'] // 2\n",
    "            hop_length = args.spec['new_hop_length'] // 2\n",
    "        if sr==256000:\n",
    "            n_fft= args.spec['new_fft'] * 2 // 3\n",
    "            hop_length = args.spec['new_hop_length'] * 2 // 3\n",
    "        if sr==384000:\n",
    "            n_fft= args.spec['new_fft']\n",
    "            hop_length = args.spec['new_hop_length']\n",
    "        \n",
    "        # Banda de frecuencias a filtrar\n",
    "        frecuencias = np.arange(0, 1 + n_fft / 2) * sr / n_fft\n",
    "        indices_freq = (frecuencias >= f_min) & (frecuencias <= f_max)\n",
    "        \n",
    "        # Reduce el paso a la mitad si sr==192000\n",
    "        img = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length, win_length=n_fft, window='hamming'))**2\n",
    "#         img = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length, win_length=n_fft, window=('kaiser', 0.0)))**2\n",
    "        img = librosa.power_to_db(img, ref=np.max)\n",
    "        img = img[indices_freq,:]\n",
    "        \n",
    "        # Specaugment\n",
    "        img = torch.from_numpy(img).unsqueeze(0)\n",
    "        if SPECAUGMENT:\n",
    "            img = spec_augment(img, time_warping_para=1, \n",
    "                               time_masking_para=36,  time_mask_num=2,\n",
    "                               frequency_masking_para=36, frequency_mask_num=2)\n",
    "        img = transforms.Normalize(mean=[0.485], std=[0.229])(img)\n",
    "        label = np.zeros(args.num_clases)\n",
    "#         if self.modo=='train' or self.modo=='valid':\n",
    "#             label[record['label_num']] = 1.0\n",
    "        \n",
    "        return {\"image\" : img, \"target\" : label, 'filename' : record['full_path'],'sr':sr,'new_fft':n_fft,'new_hop_length':hop_length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(arquitectura,clases):\n",
    "    model = timm.create_model(arquitectura, pretrained=False, num_classes=clases, in_chans=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pl = widgets.Output()\n",
    "out_pl2 = widgets.Output()\n",
    "out_pl3 = widgets.Output()\n",
    "out_pl4 = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify(change):\n",
    "    torch.cuda.empty_cache()\n",
    "    paths=[]\n",
    "    array = ['Ppip', 'Pnat-Pkuh','Ppyg-Msch','Hsav']\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d%H%M\")\n",
    "    for (dirpath, dirnames, filenames) in walk(fc.selected_path):\n",
    "            for t in filenames:\n",
    "                if t.endswith('.wav'):\n",
    "                    completo=fc.selected_path+'/'+t\n",
    "                    paths.append(str(completo))\n",
    "    lista_modelos=[]\n",
    "    aux=fc1.selected_path+'/SPECIES/'\n",
    "    i=0\n",
    "    for (folder, subfolder, file) in os.walk(aux):\n",
    "            for filename in file:\n",
    "                if filename.endswith('.bin'):\n",
    "                    lista_modelos.append(folder+'/'+filename)\n",
    "    df = DataFrame (paths,columns=['full_path'])\n",
    "    inferenceset = SedDataset(df = df)\n",
    "    inference_loader = DataLoader(inferenceset, batch_size=1, shuffle=False, drop_last=False, num_workers=2)\n",
    "    diccionario={}\n",
    "    etiquetas_ord = ['BACK', 'Barb', 'Hsav', 'Myot', 'NOISE', 'Nyct', 'Plec', 'Pnat-Pkuh', 'Ppip','Ppyg-Msch','Rhin']\n",
    "#     etiquetas_ord=etiquetas_ord.upper()\n",
    "    y_intervalos=[]\n",
    "    y_name_files=[]\n",
    "    new_y_pred=[]\n",
    "    new_name_files=[]\n",
    "    new_intervalos=[]\n",
    "    arquitecturas=[]\n",
    "    output_path=fc2.selected_path\n",
    "    if output_path is None:\n",
    "        output_path=\"/home/rasieira/Escritorio/\"\n",
    "    for b in lista_modelos:\n",
    "        arquitectura=(b.split('/')[-2]).lower()\n",
    "        if arquitectura=='resnext50':\n",
    "            arquitectura='resnext50_32x4d'\n",
    "        arquitecturas.append(arquitectura)\n",
    "    numero_modelos=len(lista_modelos)\n",
    "    for b in arquitecturas:\n",
    "        diccionario[b]=[]\n",
    "    for b in lista_modelos:\n",
    "        arquitectura=(b.split('/')[-2]).lower()\n",
    "        if arquitectura=='resnext50':\n",
    "            arquitectura='resnext50_32x4d'\n",
    "        model=Model(arquitectura,len(etiquetas_ord))\n",
    "        model.load_state_dict(torch.load(b))\n",
    "        diccionario[arquitectura].append(model)\n",
    "    final_arquitecturas=set(arquitecturas)\n",
    "    resultados=[]\n",
    "    inferiores=[]\n",
    "    superiores=[]\n",
    "    nombres=[]\n",
    "    modelos=[]\n",
    "    with out_pl:\n",
    "        with torch.no_grad():\n",
    "            outer=tqdm(inference_loader)\n",
    "            preds_df_max_sample=[]\n",
    "            model_sample=[]\n",
    "            numero_muestras=len(outer)\n",
    "            #Recorremos cada audio\n",
    "            for sample in outer:\n",
    "                input=torch.stack(sample['images']).float().to(device)\n",
    "                preds_df_max_batch=[]\n",
    "                #Recorremos el batch de segmentos de un audio\n",
    "                for i in trange(0,len(input),args.spec['batch'],leave=False):\n",
    "                    pos_fin=args.spec['batch']+i\n",
    "                    if pos_fin>len(input):\n",
    "                        pos_fin=len(input)\n",
    "                    img_batch=input[i:pos_fin]\n",
    "                    model_batch=[]\n",
    "                    preds_df_max_arquitectura=[]\n",
    "                    #Recorremos los modelos\n",
    "                    for a in diccionario:\n",
    "                        pred_list=[]\n",
    "                        models_arquitectura=[]\n",
    "                        model_list=[]\n",
    "                        #recorremos los folds de cada modelo\n",
    "                        for p in diccionario[a]:\n",
    "                            model=p\n",
    "                            model.to(device).eval()\n",
    "                            output = model(img_batch.float().to(device))\n",
    "                            y_pred=torch.sigmoid(output).detach().cpu().numpy()\n",
    "                            pred_list.append(y_pred)\n",
    "                            del model\n",
    "                            torch.cuda.empty_cache()\n",
    "                        y_pred=np.stack(pred_list)\n",
    "                        y_pred=y_pred.max(axis=0)\n",
    "                        preds_df_max_arquitectura.append(y_pred)\n",
    "                        modelos.append([a]*len(np.arange(i,pos_fin)))\n",
    "                        inferiores.append([sample['intervalos'][k][0].cpu().numpy()[0] for k in np.arange(i,pos_fin)])\n",
    "                        superiores.append([sample['intervalos'][k][1].cpu().numpy()[0] for k in np.arange(i,pos_fin)])\n",
    "                        nombres.append([sample['name_files'][k][0] for k in np.arange(i,pos_fin)])    \n",
    "                    preds_df_max_batch.append(np.vstack(preds_df_max_arquitectura))\n",
    "                outer.update(1)\n",
    "                resultados.append(np.vstack(preds_df_max_batch))\n",
    "            outer.close()\n",
    "    resultados=np.vstack(resultados)\n",
    "    df_preds = pd.DataFrame(resultados,columns=etiquetas_ord)\n",
    "    vector=df_preds.idxmax(axis=1)\n",
    "    df_preds['Prediction']=np.array(vector)\n",
    "    df_preds['name_file']=np.concatenate(nombres)\n",
    "    df_preds['inf']=np.concatenate(inferiores)\n",
    "    df_preds['sup']=np.concatenate(superiores)\n",
    "    df_preds['model']=np.concatenate(modelos)\n",
    "    df_preds=df_preds[['name_file','inf','sup','model']+etiquetas_ord+['Prediction']]\n",
    "    categorias=['5/','4/','3/','2/','1/']\n",
    "    if not os.path.exists(str(output_path)):\n",
    "        os.makedirs(str(output_path))\n",
    "    if not os.path.exists(str(output_path)+'/MULTIPLES/'):\n",
    "        os.makedirs(str(output_path)+'/MULTIPLES/')\n",
    "    if not os.path.exists(str(output_path)+'/SIMPLES/'):\n",
    "        os.makedirs(str(output_path)+'/SIMPLES/')\n",
    "    \n",
    "    if not os.path.exists(str(output_path)+'/MULTIPLES/GRUPOS_FONICOS/'):\n",
    "        os.makedirs(str(output_path)+'/MULTIPLES/GRUPOS_FONICOS/')\n",
    "    if not os.path.exists(str(output_path)+'/SIMPLES/GRUPOS_FONICOS/'):\n",
    "        os.makedirs(str(output_path)+'/SIMPLES/GRUPOS_FONICOS/')\n",
    "    aux=etiquetas_ord.copy()\n",
    "    for a in etiquetas_ord:\n",
    "            if not os.path.exists(str(output_path)+'/MULTIPLES/GRUPOS_FONICOS/PPIT/'+a+'/') and a in array:\n",
    "                os.makedirs(str(output_path)+'/MULTIPLES/GRUPOS_FONICOS/PPIT/'+a+'/')\n",
    "            if not os.path.exists(str(output_path)+'/MULTIPLES/GRUPOS_FONICOS/'+a+'/') and a not in array:\n",
    "                os.makedirs(str(output_path)+'/MULTIPLES/GRUPOS_FONICOS/'+a+'/')\n",
    "            if not os.path.exists(str(output_path)+'/SIMPLES/GRUPOS_FONICOS/PPIT/'+a+'/') and a in array:\n",
    "                os.makedirs(str(output_path)+'/SIMPLES/GRUPOS_FONICOS/PPIT/'+a+'/')\n",
    "            if not os.path.exists(str(output_path)+'/SIMPLES/GRUPOS_FONICOS/'+a+'/') and a not in array:\n",
    "                os.makedirs(str(output_path)+'/SIMPLES/GRUPOS_FONICOS/'+a+'/')\n",
    "            for t in categorias:\n",
    "                if not os.path.exists(str(output_path)+'/MULTIPLES/GRUPOS_FONICOS/PPIT/'+a+'/'+t+'/') and a in array:\n",
    "                    os.makedirs(str(output_path)+'/MULTIPLES/GRUPOS_FONICOS/PPIT/'+a+'/'+t+'/')\n",
    "                if not os.path.exists(str(output_path)+'/MULTIPLES/GRUPOS_FONICOS/'+a+'/'+t+'/') and a not in array:\n",
    "                    os.makedirs(str(output_path)+'/MULTIPLES/GRUPOS_FONICOS/'+a+'/'+t+'/')\n",
    "                if not os.path.exists(str(output_path)+'/SIMPLES/GRUPOS_FONICOS/PPIT/'+a+'/'+t+'/') and a in array:\n",
    "                    os.makedirs(str(output_path)+'/SIMPLES/GRUPOS_FONICOS/PPIT/'+a+'/'+t+'/')\n",
    "                if not os.path.exists(str(output_path)+'/SIMPLES/GRUPOS_FONICOS/'+a+'/'+t+'/') and a not in array:\n",
    "                    os.makedirs(str(output_path)+'/SIMPLES/GRUPOS_FONICOS/'+a+'/'+t+'/') \n",
    "    umbral_murcielagos=umbral_groups.value\n",
    "    porcentaje_aparicion=aparicion_species.value\n",
    "    path_csv=str(output_path)+'/'+str(date_time)+'resultados.csv'\n",
    "    aux_df_preds=df_preds.copy()\n",
    "    aux_df_preds['name_file']=aux_df_preds['name_file'].str.split('/').str[-1]\n",
    "    aux_df_preds.to_csv(path_csv,index=False)\n",
    "    mat=df_preds.copy()\n",
    "    mat2=mat.copy()\n",
    "    diccionario={}\n",
    "    for a in etiquetas_ord:\n",
    "        mat2[a]=(mat2[a]>umbral_murcielagos)\n",
    "        mat3=mat2.groupby(['name_file','model'],as_index=False)[[a]].mean()\n",
    "        mat3[a]=(mat3[a]>porcentaje_aparicion)\n",
    "        mat4=mat3.groupby(['name_file'],as_index=False)[[a]].sum()\n",
    "        diccionario[a]=np.stack(mat4[a].values)\n",
    "    final = pd.DataFrame.from_dict(diccionario)\n",
    "    final['name_file']=mat4['name_file']\n",
    "    a=final[etiquetas_ord]\n",
    "    new = a.eq(a.max(axis=1), axis=0)\n",
    "    o = new.mul(new.columns.to_series()).apply(','.join, axis=1).str.strip(',')\n",
    "    t=[]\n",
    "    for a in o:\n",
    "        lista=a.replace(',',' ').split(' ')\n",
    "        t.append([item for item in lista if item])\n",
    "    final['Prediction']=np.array(t)\n",
    "    for index,row in final.iterrows():\n",
    "        original=row['name_file']\n",
    "        name_file=original.split('/')[-1]\n",
    "        if len(row['Prediction'])!=1:\n",
    "            for a in row['Prediction']:\n",
    "                if str(a) in array:\n",
    "                    target=str(output_path)+'/MULTIPLES/GRUPOS_FONICOS/PPIT/'+str(a)+'/'+str(row[a])+'/'+name_file\n",
    "                else:\n",
    "                    target=str(output_path)+'/MULTIPLES/GRUPOS_FONICOS/'+str(a)+'/'+str(row[a])+'/'+name_file\n",
    "                if not(os.path.exists(target)):\n",
    "                    copyfile(original,target)\n",
    "        else:\n",
    "                if str(row['Prediction'][0]) in array:\n",
    "                    target=str(output_path)+'/SIMPLES/GRUPOS_FONICOS/PPIT/'+str(row['Prediction'][0])+'/'+str(row[row['Prediction'][0]])+'/'+name_file\n",
    "                else:\n",
    "                    target=str(output_path)+'/SIMPLES/GRUPOS_FONICOS/'+str(row['Prediction'][0])+'/'+str(row[row['Prediction'][0]])+'/'+name_file\n",
    "                if not(os.path.exists(target)):\n",
    "                    copyfile(original,target)\n",
    "        if os.path.exists(original):\n",
    "            os.remove(original)\n",
    "    final['Prediction']=final['Prediction'].astype(str)\n",
    "    final['Prediction']=final['Prediction'].str.replace(\"[\",\"\").str.replace(\"]\",\"\").str.replace('\"','').str.replace(\"'\",\"\")\n",
    "    final['name_file']=final['name_file'].str.split('/').str[-1]\n",
    "    final.to_csv(str(output_path)+'/'+str(date_time)+'votesbyfile.csv',index=False)\n",
    "    with out_pl:   \n",
    "        display(final)\n",
    "        display(aux_df_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify_2(change):\n",
    "    torch.cuda.empty_cache()\n",
    "    paths=[]\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d%H%M\")\n",
    "    for (dirpath, dirnames, filenames) in walk(fc3.selected_path):\n",
    "            for t in filenames:\n",
    "                if t.endswith('.wav'):\n",
    "                    completo=fc3.selected_path+'/'+t\n",
    "                    paths.append(str(completo))\n",
    "    lista_modelos=[]\n",
    "    aux=fc4.selected_path+'/NOISE/'\n",
    "    output_path=fc5.selected_path\n",
    "    if output_path is None:\n",
    "        output_path=\"/home/rasieira/Escritorio/\"\n",
    "    i=0\n",
    "    for (folder, subfolder, file) in os.walk(aux):\n",
    "            for filename in file:\n",
    "                if filename.endswith('.bin'):\n",
    "                    lista_modelos.append(folder+'/'+filename)\n",
    "    df = DataFrame (paths,columns=['full_path'])\n",
    "    inferenceset = SedDataset(df = df)\n",
    "    inference_loader = DataLoader(inferenceset, batch_size=1, shuffle=False, drop_last=False, num_workers=2)\n",
    "    diccionario={}\n",
    "    etiquetas_ord = ['BATS', 'NOISE']\n",
    "    y_intervalos=[]\n",
    "    y_name_files=[]\n",
    "    new_y_pred=[]\n",
    "    new_name_files=[]\n",
    "    new_intervalos=[]\n",
    "    arquitecturas=[]\n",
    "    for b in lista_modelos:\n",
    "        arquitectura=(b.split('/')[-2]).lower()\n",
    "        if arquitectura=='resnext50':\n",
    "            arquitectura='resnext50_32x4d'\n",
    "        arquitecturas.append(arquitectura)\n",
    "    numero_modelos=len(lista_modelos)\n",
    "    for b in arquitecturas:\n",
    "        diccionario[b]=[]\n",
    "    for b in lista_modelos:\n",
    "        arquitectura=(b.split('/')[-2]).lower()\n",
    "        if arquitectura=='resnext50':\n",
    "            arquitectura='resnext50_32x4d'\n",
    "        model=Model(arquitectura,len(etiquetas_ord))\n",
    "        model.load_state_dict(torch.load(b))\n",
    "        diccionario[arquitectura].append(model)\n",
    "    final_arquitecturas=set(arquitecturas)\n",
    "    resultados=[]\n",
    "    inferiores=[]\n",
    "    superiores=[]\n",
    "    nombres=[]\n",
    "    modelos=[]\n",
    "    with out_pl2:\n",
    "        with torch.no_grad():\n",
    "            outer=tqdm(inference_loader)\n",
    "            preds_df_max_sample=[]\n",
    "            model_sample=[]\n",
    "            numero_muestras=len(outer)\n",
    "            #Recorremos cada audio\n",
    "            for sample in outer:\n",
    "                input=torch.stack(sample['images']).float().to(device)\n",
    "                preds_df_max_batch=[]\n",
    "                #Recorremos el batch de segmentos de un audio\n",
    "                for i in trange(0,len(input),args.spec['batch'],leave=False):\n",
    "                    pos_fin=args.spec['batch']+i\n",
    "                    if pos_fin>len(input):\n",
    "                        pos_fin=len(input)\n",
    "                    img_batch=input[i:pos_fin]\n",
    "                    model_batch=[]\n",
    "                    preds_df_max_arquitectura=[]\n",
    "                    #Recorremos los modelos\n",
    "                    for a in diccionario:\n",
    "                        pred_list=[]\n",
    "                        models_arquitectura=[]\n",
    "                        model_list=[]\n",
    "                        #recorremos los folds de cada modelo\n",
    "                        for p in diccionario[a]:\n",
    "                            model=p\n",
    "                            model.to(device).eval()\n",
    "                            output = model(img_batch.float().to(device))\n",
    "                            y_pred=torch.sigmoid(output).detach().cpu().numpy()\n",
    "                            pred_list.append(y_pred)\n",
    "                            del model\n",
    "                            torch.cuda.empty_cache()\n",
    "                        y_pred=np.stack(pred_list)\n",
    "                        y_pred=y_pred.max(axis=0)\n",
    "                        preds_df_max_arquitectura.append(y_pred)\n",
    "                        modelos.append([a]*len(np.arange(i,pos_fin)))\n",
    "                        inferiores.append([sample['intervalos'][k][0].cpu().numpy()[0] for k in np.arange(i,pos_fin)])\n",
    "                        superiores.append([sample['intervalos'][k][1].cpu().numpy()[0] for k in np.arange(i,pos_fin)])\n",
    "                        nombres.append([sample['name_files'][k][0] for k in np.arange(i,pos_fin)])    \n",
    "                    preds_df_max_batch.append(np.vstack(preds_df_max_arquitectura))\n",
    "                outer.update(1)\n",
    "                resultados.append(np.vstack(preds_df_max_batch))\n",
    "            outer.close()\n",
    "    resultados=np.vstack(resultados)\n",
    "    df_preds = pd.DataFrame(resultados,columns=etiquetas_ord)\n",
    "    vector=df_preds.idxmax(axis=1)\n",
    "    df_preds['Prediction']=np.array(vector)\n",
    "    df_preds['inf']=np.concatenate(inferiores)\n",
    "    df_preds['sup']=np.concatenate(superiores)\n",
    "    df_preds['model']=np.concatenate(modelos)\n",
    "    df_preds['name_file']=np.concatenate(nombres)\n",
    "    df_preds=df_preds[['name_file','inf','sup','model']+etiquetas_ord+['Prediction']]\n",
    "    if not os.path.exists(str(output_path)+'/OUTPUT/'):\n",
    "        os.makedirs(str(output_path)+'/OUTPUT/')\n",
    "    if not os.path.exists(str(output_path)+'/OUTPUT/NOISE/'):\n",
    "        os.makedirs(str(output_path)+'/OUTPUT/NOISE/')\n",
    "    if not os.path.exists(str(output_path)+'/OUTPUT/BATS/'):\n",
    "        os.makedirs(str(output_path)+'/OUTPUT/BATS/')\n",
    "    path_csv=str(output_path)+'/OUTPUT/'+str(date_time)+'resultados.csv'\n",
    "    aux_df_preds=df_preds.copy()\n",
    "    aux_df_preds['name_file']=aux_df_preds['name_file'].str.split('/').str[-1]\n",
    "    aux_df_preds.to_csv(path_csv,index=False)\n",
    "    umbral_murcielagos=float(umbral_bats.value)\n",
    "    umbral_noise=float(umbral_ruido.value)\n",
    "    porcentaje_aparicion=float(aparicion_noise.value)\n",
    "    mat=df_preds.copy()\n",
    "    mat2=mat.copy()\n",
    "    mat2['BATS']=(mat2['BATS']>umbral_murcielagos)\n",
    "    mat2['NOISE']=(mat2['NOISE']>umbral_noise)\n",
    "    aux_mat_2=mat2.copy()\n",
    "    aux_mat_2['name_file']=aux_mat_2['name_file'].str.split('/').str[-1]\n",
    "    aux_mat_2.to_csv(str(output_path)+'/OUTPUT/'+'/'+str(date_time)+'resultados_binary.csv',index=False)\n",
    "    mat3=mat2.groupby(['name_file','model'],as_index=False)[['BATS','NOISE']].mean()\n",
    "    mat3['BATS']=(mat3['BATS']>porcentaje_aparicion)\n",
    "    mat3['NOISE']=(mat3['NOISE']>porcentaje_aparicion)\n",
    "    aux_mat_3=mat3.copy()\n",
    "    aux_mat_3['name_file']=aux_mat_3['name_file'].str.split('/').str[-1]\n",
    "    aux_mat_3.to_csv(str(output_path)+'/OUTPUT/'+'/'+str(date_time)+'resultados_votebymodel.csv',index=False)\n",
    "    mat4=mat3.groupby(['name_file'],as_index=False)[['BATS','NOISE']].sum()\n",
    "    aux_mat_4=mat4.copy()\n",
    "    aux_mat_4['name_file']=aux_mat_4['name_file'].str.split('/').str[-1] \n",
    "    aux_mat_4.to_csv(str(output_path)+'/OUTPUT/'+'/'+str(date_time)+'resultados_votes.csv',index=False)\n",
    "    maxValueIndex = mat4[['NOISE','BATS']].idxmax(axis=1)\n",
    "    mat4['Prediction']=np.array(maxValueIndex)\n",
    "    for index,row in mat4.iterrows():\n",
    "        original=row['name_file']\n",
    "        name_file=original.split('/')[-1]\n",
    "        target=str(output_path)+'/OUTPUT/'+str(row['Prediction'])+'/'+name_file\n",
    "        if not(os.path.exists(target)):\n",
    "            copyfile(original,target)\n",
    "    with out_pl2:\n",
    "        display(aux_df_preds)\n",
    "        display(aux_mat_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify_3(change):\n",
    "    output_path=fc7.selected_path\n",
    "    if output_path is None:\n",
    "        output_path=\"/home/rasieira/Escritorio/\"\n",
    "    SPECAUGMENT = False\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d%H%M\")\n",
    "    with out_pl3:\n",
    "        seed_everything(1234)\n",
    "        paths=[]\n",
    "        for root, dirs, files in os.walk(fc6.selected_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".wav\"):\n",
    "                     paths.append(os.path.join(root, file))\n",
    "        df = DataFrame (paths,columns=['full_path'])\n",
    "        display(df)\n",
    "        validset = SedDatasetNoInterval(df = df, audio_transform=None, modo=\"valid\")\n",
    "        valid_loader = DataLoader(validset, batch_size=1, shuffle=False, drop_last=False, num_workers=0)\n",
    "        for i, entrada in enumerate(tqdm(valid_loader)):\n",
    "                fig, ax = plt.subplots()\n",
    "                fig.set_figheight(10)\n",
    "                fig.set_figwidth(20)\n",
    "                arr=entrada['image'].cpu().numpy()[0,0,:,:]\n",
    "#                 newArr=np.where(abs(arr)>100,0,100)\n",
    "                img = librosa.display.specshow(arr,\n",
    "                                               fmin=args.spec['new_fmin'],\n",
    "                                               cmap='gray_r',\n",
    "                                               fmax=args.spec['new_fmax'],\n",
    "                                               hop_length=entrada['new_hop_length'].cpu().numpy(),\n",
    "                                               sr=entrada['sr'].cpu().numpy(),\n",
    "                                               x_axis='time', \n",
    "                                               y_axis=None, \n",
    "                                               ax=ax)\n",
    "                freq_labels = np.linspace(args.spec['new_fmin'], args.spec['new_fmax'], 10).astype(int)\n",
    "                freq_labels_pos = np.linspace(0,entrada['image'].cpu().numpy()[0,0,:,:].shape[0],len(freq_labels)).astype(int)\n",
    "                plt.yticks(freq_labels_pos, freq_labels);\n",
    "                fig.colorbar(img, ax=ax, format=\"%+2.f dB\");\n",
    "                nombre=entrada['filename'][0].split('/')[-1].split('.')[0]\n",
    "                plt.title(nombre)\n",
    "                plt.savefig(entrada['filename'][0].split('.')[0]+'.png', bbox_inches='tight');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser('../')\n",
    "\n",
    "# # Print the selected path, filename, or both\n",
    "# if fc.selected_path is not None:\n",
    "#     print(fc.selected_path)\n",
    "# if fc.selected_filename is not None:\n",
    "#     print(fc.selected_filename)\n",
    "# if fc.selected is not None:\n",
    "#     print(fc.selected)\n",
    "\n",
    "# Change defaults and reset the dialog\n",
    "fc.default_path = '/home/rasieira/Escritorio/OUTPUT/BATS/'\n",
    "\n",
    "# Change hidden files\n",
    "fc.show_hidden = True\n",
    "\n",
    "# Show or hide folder icons\n",
    "fc.use_dir_icons = True\n",
    "\n",
    "# Switch to folder-only mode\n",
    "fc.show_only_dirs = False\n",
    "\n",
    "# Change the title (use '' to hide)\n",
    "fc.title = '<b>Selecciona el INPUT</b>'\n",
    "\n",
    "fc1 = FileChooser('../')\n",
    "\n",
    "# Print the selected path, filename, or both\n",
    "# if fc1.selected_path is not None:\n",
    "#     print(fc1.selected_path)\n",
    "# if fc1.selected_filename is not None:\n",
    "#     print(fc1.selected_filename)\n",
    "# if fc1.selected is not None:\n",
    "#     print(fc1.selected)\n",
    "\n",
    "# Change defaults and reset the dialog\n",
    "fc1.default_path = '/home/rasieira/Escritorio/modelos/'\n",
    "\n",
    "\n",
    "# Change hidden files\n",
    "fc1.show_hidden = True\n",
    "\n",
    "# Show or hide folder icons\n",
    "fc1.use_dir_icons = True\n",
    "\n",
    "# Switch to folder-only mode\n",
    "fc1.show_only_dirs = False\n",
    "\n",
    "# Change the title (use '' to hide)\n",
    "fc1.title = '<b>Selecciona la carpetas con los Modelos(.bin)</b>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2 = FileChooser('../')\n",
    "\n",
    "# Print the selected path, filename, or both\n",
    "# if fc2.selected_path is not None:\n",
    "#     print(fc2.selected_path)\n",
    "# if fc2.selected_filename is not None:\n",
    "#     print(fc2.selected_filename)\n",
    "# if fc2.selected is not None:\n",
    "#     print(fc2.selected)\n",
    "\n",
    "# Change defaults and reset the dialog\n",
    "fc2.default_path = '/home/rasieira/Escritorio/OUTPUT/BATS/'\n",
    "# Change hidden files\n",
    "fc2.show_hidden = True\n",
    "\n",
    "# Show or hide folder icons\n",
    "fc2.use_dir_icons = True\n",
    "\n",
    "# Switch to folder-only mode\n",
    "fc2.show_only_dirs = False\n",
    "\n",
    "# Change the title (use '' to hide)\n",
    "fc2.title = '<b>Selecciona el OUTPUT de los RESULTADOS</b>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_run = widgets.Button(description='Sacar Predicciones Ruido')\n",
    "btn_run.on_click(on_click_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc3 = FileChooser('../')\n",
    "\n",
    "# Print the selected path, filename, or both\n",
    "# if fc2.selected_path is not None:\n",
    "#     print(fc2.selected_path)\n",
    "# if fc2.selected_filename is not None:\n",
    "#     print(fc2.selected_filename)\n",
    "# if fc2.selected is not None:\n",
    "#     print(fc2.selected)\n",
    "\n",
    "# Change defaults and reset the dialog\n",
    "fc3.default_path = '/home/rasieira/Escritorio/INPUT/'\n",
    "# Change hidden files\n",
    "fc3.show_hidden = True\n",
    "\n",
    "# Show or hide folder icons\n",
    "fc3.use_dir_icons = True\n",
    "\n",
    "# Switch to folder-only mode\n",
    "fc3.show_only_dirs = False\n",
    "\n",
    "# Change the title (use '' to hide)\n",
    "fc3.title = '<b>Selecciona el INPUT de los AUDIOS(con ruido)</b>'\n",
    "fc4 = FileChooser('../')\n",
    "\n",
    "# Print the selected path, filename, or both\n",
    "# if fc2.selected_path is not None:\n",
    "#     print(fc2.selected_path)\n",
    "# if fc2.selected_filename is not None:\n",
    "#     print(fc2.selected_filename)\n",
    "# if fc2.selected is not None:\n",
    "#     print(fc2.selected)\n",
    "\n",
    "# Change defaults and reset the dialog\n",
    "fc4.default_path = '/home/rasieira/Escritorio/modelos/'\n",
    "# Change hidden files\n",
    "fc4.show_hidden = True\n",
    "\n",
    "# Show or hide folder icons\n",
    "fc4.use_dir_icons = True\n",
    "\n",
    "# Switch to folder-only mode\n",
    "fc4.show_only_dirs = False\n",
    "\n",
    "# Change the title (use '' to hide)\n",
    "fc4.title = '<b>Selecciona la carpetas con los Modelos(.bin)</b>'\n",
    "fc5 = FileChooser('../')\n",
    "\n",
    "# Print the selected path, filename, or both\n",
    "# if fc2.selected_path is not None:\n",
    "#     print(fc2.selected_path)\n",
    "# if fc2.selected_filename is not None:\n",
    "#     print(fc2.selected_filename)\n",
    "# if fc2.selected is not None:\n",
    "#     print(fc2.selected)\n",
    "\n",
    "# Change defaults and reset the dialog\n",
    "fc5.default_path = '/home/rasieira/Escritorio/'\n",
    "# Change hidden files\n",
    "fc5.show_hidden = True\n",
    "\n",
    "# Show or hide folder icons\n",
    "fc5.use_dir_icons = True\n",
    "\n",
    "# Switch to folder-only mode\n",
    "fc5.show_only_dirs = False\n",
    "\n",
    "# Change the title (use '' to hide)\n",
    "fc5.title = '<b>Selecciona el OUTPUT de los RESULTADOS</b>'\n",
    "btn_run_2 = widgets.Button(description='Sacar Predicciones Grupos/Subgrupos')\n",
    "btn_run_2.on_click(on_click_classify_2)\n",
    "aparicion_noise=widgets.BoundedFloatText(\n",
    "    value=0.1,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    description='aparicion',\n",
    "    disabled=False)\n",
    "umbral_ruido=widgets.BoundedFloatText(\n",
    "    value=0.65,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    description='umbral noise',\n",
    "    disabled=False)\n",
    "umbral_bats=widgets.BoundedFloatText(\n",
    "    value=0.95,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    description='umbral bats',\n",
    "    disabled=False)\n",
    "umbral_groups=widgets.BoundedFloatText(\n",
    "    value=0.98,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    description='umbral conf',\n",
    "    disabled=False)\n",
    "aparicion_species=widgets.BoundedFloatText(\n",
    "    value=0.1,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    description='aparicion',\n",
    "    disabled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc6 = FileChooser('../')\n",
    "\n",
    "# Print the selected path, filename, or both\n",
    "# if fc2.selected_path is not None:\n",
    "#     print(fc2.selected_path)\n",
    "# if fc2.selected_filename is not None:\n",
    "#     print(fc2.selected_filename)\n",
    "# if fc2.selected is not None:\n",
    "#     print(fc2.selected)\n",
    "\n",
    "# Change defaults and reset the dialog\n",
    "fc6.default_path = '/home/rasieira/Escritorio/OUTPUT/BATS/MULTIPLES/'\n",
    "# fc6.default_path = '/home/rasieira/Escritorio/INPUT/'\n",
    "# Change hidden files\n",
    "fc6.show_hidden = True\n",
    "\n",
    "# Show or hide folder icons\n",
    "fc6.use_dir_icons = True\n",
    "\n",
    "# Switch to folder-only mode\n",
    "fc6.show_only_dirs = True\n",
    "\n",
    "# Change the title (use '' to hide)\n",
    "fc6.title = '<b>Selecciona el INPUT de los AUDIOS(con ruido)</b>'\n",
    "fc7 = FileChooser('../')\n",
    "\n",
    "# Print the selected path, filename, or both\n",
    "# if fc2.selected_path is not None:\n",
    "#     print(fc2.selected_path)\n",
    "# if fc2.selected_filename is not None:\n",
    "#     print(fc2.selected_filename)\n",
    "# if fc2.selected is not None:\n",
    "#     print(fc2.selected)\n",
    "\n",
    "# Change defaults and reset the dialog\n",
    "fc7.default_path = '/home/rasieira/Escritorio/OUTPUT/BATS/MULTIPLES/'\n",
    "# fc7.default_path = '/home/rasieira/Escritorio/OUTPUT/'\n",
    "# Change hidden files\n",
    "fc7.show_hidden = True\n",
    "\n",
    "# Show or hide folder icons\n",
    "fc7.use_dir_icons = True\n",
    "\n",
    "# Switch to folder-only mode\n",
    "fc7.show_only_dirs = True\n",
    "\n",
    "# Change the title (use '' to hide)\n",
    "fc7.title = '<b>Selecciona el OUTPUT de los RESULTADOS</b>'\n",
    "btn_run_3 = widgets.Button(description='Sacar Predicciones Grupos/Subgrupos')\n",
    "btn_run_3.on_click(on_click_classify_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p><br></p>\n",
    "<p><strong>Para eliminar ruido</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76308d172cae458787bf4d8c31e2f62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileChooser(path='/home/rasieira/Escritorio/INPUT', filename='', title='HTML(value='<b>Seleccio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VBox([fc3,fc4,fc5,aparicion_noise,umbral_ruido,umbral_bats,btn_run_2,out_pl2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p><br></p>\n",
    "<p><strong>Para clasificar grupos fonicos y el subgrupo PPIT</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfc26308c38426d987c4fdf3a255b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileChooser(path='/home/rasieira/Escritorio/OUTPUT/BATS', filename='', title='HTML(value='<b>Se…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VBox([fc,fc1,fc2,aparicion_species,umbral_groups,btn_run,out_pl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p><br></p>\n",
    "<p><strong>Para generar los spectogramas</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c10ed284614af19a44f8b9326fd27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileChooser(path='/home/rasieira/Escritorio/OUTPUT/BATS/MULTIPLES', filename='', title='HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VBox([fc6,fc7,btn_run_3,out_pl3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
